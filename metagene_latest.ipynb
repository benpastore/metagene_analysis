{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fbd3bed5-65e5-4d31-af71-6ff8c8a101c9",
   "metadata": {},
   "source": [
    "# *Metagenome analysis pipeline part 2/2*\n",
    "\n",
    "First run align.sh to align and normalize sequencing reads. Then use this to visualize the metagene pattern.\n",
    "\n",
    "This pipeline is designed to be used primarily with small RNA sequencing data but can be adapted to all sequencing methods.\n",
    "\n",
    "Inputs :\n",
    "* bed file **or** directory with bed files\n",
    "    * the form of bedfiles is as follows\n",
    "        1. chrom (or gene)\n",
    "        2. start pos of read\n",
    "        3. end pos of read\n",
    "        4. sequence of read\n",
    "        5. abundance of the read\n",
    "        6. strand\n",
    "* transcript fasta file or bed windows\n",
    "    * if using bed windows reads that fall witin these windows will be counted, if scaling is enabled the size of the window will be used for scaling.\n",
    "        * Format \n",
    "            1. chrom (or gene)\n",
    "            2. start \n",
    "            3. end\n",
    "    * if transcript fasta file is provided but not bed windows, the length of the transcripts will be used for scaling.\n",
    "    \n",
    "Other parameters : \n",
    "* scaling --> default is True\n",
    "* sample --> if None will use basename of bed file with reads.\n",
    "* 5' nucleotide (p5nt) --> G or A\n",
    "* min_len --> 21 nt\n",
    "* max_len --> 23 nt\n",
    "\n",
    "\n",
    "Tip :  \n",
    "* use %%bash in cell to reformat bed.tsv file from output of nextflow_smRNA pipeline\n",
    "\n",
    "**If using bed directory with bed files, use run_metagene_multi(), otherwise can use run_metagene()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cb076f9-ee2c-43eb-a20a-6dd4f9b9f38b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd \n",
    "import argparse\n",
    "import numpy as np \n",
    "import glob\n",
    "import time \n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fdcfe4fe-53a3-41e5-9714-faed38a080aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarise_target_transcripts(bed_file) : \n",
    "    bed = pd.read_csv(bed_file, \n",
    "                    sep = \"\\t\",\n",
    "                    usecols = [0,1,2,6,7,8],\n",
    "                    names = ['chrom', 'start', 'end', 'transcript_start', 'transcript_end', 'ee_junc'])\n",
    "\n",
    "    print(bed.head())\n",
    "    \n",
    "    bed = bed.query(\"transcript_end < 10000\")\n",
    "\n",
    "    print(f\"Mean transcript length: {bed['transcript_end'].mean()}\")\n",
    "\n",
    "    print(f\"Median transcript length: {bed['transcript_end'].median()}\")\n",
    "    \n",
    "    fig, ax =plt.subplots(1,2)\n",
    "    \n",
    "    p = sns.histplot(data=bed, x=\"transcript_end\", ax=ax[0])\n",
    "    \n",
    "    bed['scaled_ee_junc'] = 100*(bed['ee_junc'] / bed['transcript_end'])\n",
    "    \n",
    "    \n",
    "    p1 = sns.histplot(data=bed, x=\"scaled_ee_junc\", ax=ax[1])\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b30749be-da22-420a-a974-c7bb24060a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metagene(result, plot_group = 'alias', facet_by = None, x_col = 'pos', y_col = 'count', shade = None, title = None, sharey = False, vline = False) : \n",
    "    \n",
    "    plot = sns.FacetGrid(result, \n",
    "                         col = facet_by, \n",
    "                         hue = plot_group, \n",
    "                         height = 4, \n",
    "                         aspect = 2)\n",
    "    \n",
    "    plot.map(sns.lineplot, x_col, y_col)\n",
    "\n",
    "    plot.add_legend()\n",
    "    \n",
    "    if shade : \n",
    "            result['m'] = result[y_col] - result[shade]\n",
    "            result['M'] = result[y_col] + result[shade]\n",
    "            plot.map(plt.fill_between, x_col, 'm', 'M', alpha=0.2)\n",
    "            \n",
    "    if vline : \n",
    "        plt.axvline(x = vline, color = 'grey', label = f'{vline} bp', alpha = 0.5)\n",
    "    \n",
    "    \n",
    "    if title : \n",
    "        plot.fig.suptitle(f'{title}')\n",
    "    \n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4b685523-90d9-4668-8c66-b991175d5e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_and_plot(conditions, result, count = 'count', vline = False) :\n",
    "    \n",
    "    result_merge = result.merge(\n",
    "        conditions, how = 'left', left_on = 'alias', right_on = 'simple_name')\n",
    "    \n",
    "    result_grouped = result_merge.groupby(\n",
    "        ['pos', 'type', 'condition']\n",
    "    ).agg(\n",
    "        M = (count, 'mean'),\n",
    "        S = (count, 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    plot_metagene(result_grouped, \n",
    "                  shade = 'S', \n",
    "                  facet_by='type', \n",
    "                  x_col = 'pos', \n",
    "                  y_col = 'M', \n",
    "                  plot_group = 'condition',\n",
    "                  vline = vline\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7ed8270a-c9c0-4de8-9dcf-27516bae227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_transcripts(transcripts) : \n",
    "    \n",
    "    sizes = {}\n",
    "    seqs = {}\n",
    "    seq = ''\n",
    "    i = 0\n",
    "    with open(transcripts, 'r') as f : \n",
    "        for line in f :\n",
    "            if line.startswith(\">\") :\n",
    "                info = line.strip().replace(\">\",\"\")\n",
    "                if i == 1 :\n",
    "                    seqs[info] = seq \n",
    "                    sizes[info] = len(seq)\n",
    "                    seq = ''\n",
    "                    i = 0\n",
    "                i += 1\n",
    "            else : \n",
    "                seq += line.strip()\n",
    "                \n",
    "    return seqs, sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "db357038-3eed-4f78-b225-7836d41036b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_windows(bed_windows) : \n",
    "\n",
    "    windows = {}\n",
    "    with open(bed_windows, 'r') as f : \n",
    "        for line in f : \n",
    "            info = line.strip().split(\"\\t\")\n",
    "            gene = info[0]\n",
    "            start = int(info[1])\n",
    "            end = int(round(float(info[2])))\n",
    "\n",
    "            if gene in windows.keys() : \n",
    "                windows[gene].append([start, end])\n",
    "            else : \n",
    "                windows[gene] = [ [start, end] ]\n",
    "    return windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2e1dec5c-1518-4754-994f-310652f906e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_coverage(bed) : \n",
    "    \n",
    "    bed_entries = 0 \n",
    "    with open(bed, 'r') as f : \n",
    "        for line in f : \n",
    "            bed_entries += 1\n",
    "    f.close()\n",
    "    print(f\"{bed_entries} total bed entries...\")\n",
    "    \n",
    "    cov = {}\n",
    "    bed_line = 0\n",
    "    with open(bed, 'r') as f :\n",
    "        for line in f : \n",
    "            if not (line.startswith('chrom')) and not (line.startswith(\"gene_name\")) : \n",
    "                info = line.strip().split('\\t')\n",
    "                chrom = info[0]\n",
    "                start = int(info[1])\n",
    "                end = int(info[2])\n",
    "                seq = str(info[3])\n",
    "                count = float(info[4])\n",
    "                \n",
    "                # make a dict for each gene\n",
    "                if not chrom in cov.keys() : \n",
    "                    cov[chrom] = {}\n",
    "                \n",
    "                for i in range(start, end + 1) :\n",
    "                    if i in cov[chrom].keys() : \n",
    "                        cov[chrom][i] += ( count / len(seq) )\n",
    "                    else : \n",
    "                        cov[chrom][i] = ( count / len(seq) )\n",
    "                        \n",
    "            bed_line += 1\n",
    "            print(f'{bed_line} of {bed_entries} ({ round(( (bed_line)/(bed_entries) )*100,2) }%) total bed entries', end='\\r')\n",
    "    f.close() \n",
    "    \n",
    "    pklf = f\"{bed}.cov.pickle\"\n",
    "    with open(pklf, 'wb') as handle : \n",
    "        pickle.dump(cov, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return cov\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4cc5e7b9-af8b-4f6b-82f8-6195f75f1f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def adjust_pos(pos) : \n",
    "    \n",
    "    if not pos == 100 and not pos == 0 : \n",
    "        return pos\n",
    "    elif pos == 100 : \n",
    "        return 99.8\n",
    "    else : \n",
    "        return 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc303acf-e2c2-4e60-898b-c3a0c09243ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sum_metagene_count_per_gene(bed, windows = None, scaling = False, transcript_sizes = None, sample = None, p5nt = ['G', 'A'], min_len = 21, max_len = 23) :\n",
    "    \n",
    "    time1 = time.time()\n",
    "        \n",
    "    pklf = f\"{bed}.cov.pickle\"\n",
    "    if not os.path.exists(pklf) : \n",
    "        cov = calculate_coverage(bed)\n",
    "    else : \n",
    "        with open(pklf, 'rb') as handle : \n",
    "            cov = pickle.load(handle)\n",
    "    \n",
    "    sample = os.path.basename(bed).split(\".\")[0]\n",
    "\n",
    "    counts = []\n",
    "    genes = []\n",
    "    if windows : \n",
    "        total_windows = len(windows.keys())\n",
    "        tracker = 0\n",
    "        for gene,win_coord in windows.items() :\n",
    "            for sub_win in win_coord :\n",
    "                if gene in cov.keys() :\n",
    "                    val = sum( [v for k,v in cov[gene].items() if sub_win[0] <= k <= sub_win[1]])\n",
    "                    if val :\n",
    "                        win_size = sub_win[1] - sub_win[0] + 1\n",
    "                        genes.append(gene)\n",
    "                        counts.append(val/win_size)\n",
    "                            \n",
    "           # tracker += 1\n",
    "            #print(f'{tracker} of {total_windows} ({ round(( (tracker)/(total_windows) )*100,2) }%) windows processed', end='\\r')\n",
    "    else : \n",
    "        total_genes = len(cov.keys())\n",
    "        tracker = 0\n",
    "        for gene,subdict in cov.items() :\n",
    "            val = sum(list(subdict.values()))\n",
    "            if val :\n",
    "                if gene in count.keys() : \n",
    "                    print(\"Multiple windows for 1 gene...exiting\")\n",
    "                    return 0\n",
    "                else : \n",
    "                    genes.append(gene)\n",
    "                    counts.append(count)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'gene' : genes, \n",
    "        f'{sample}' : counts\n",
    "    })\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8d1781c2-74e4-4e8a-b216-e1a49480e7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_metagene_coord(bed, windows = None, scaling = False, transcript_sizes = None, sample = None, p5nt = ['G', 'A'], min_len = 21, max_len = 23) :\n",
    "    \n",
    "    time1 = time.time()\n",
    "        \n",
    "    pklf = f\"{bed}.cov.pickle\"\n",
    "    if not os.path.exists(pklf) : \n",
    "        cov = calculate_coverage(bed)\n",
    "    else : \n",
    "        with open(pklf, 'rb') as handle : \n",
    "            cov = pickle.load(handle)\n",
    "    \n",
    "    positions = []\n",
    "    counts = []\n",
    "    if windows : \n",
    "        total_windows = len(windows.keys())\n",
    "        tracker = 0\n",
    "        for gene,win_coord in windows.items() :\n",
    "            for sub_win in win_coord :\n",
    "                if gene in cov.keys() : \n",
    "                    cov_sub = { k:v for k,v in cov[gene].items() if sub_win[0] <= k <= sub_win[1] }\n",
    "\n",
    "                    if bool(cov_sub) : \n",
    "                        win_size = sub_win[1] - sub_win[0] + 1\n",
    "\n",
    "                        if scaling :\n",
    "                            cov_sub_scaled = [ [(round(100*( (k-sub_win[0])/win_size)*5)/5), v] for k,v in cov_sub.items() ] \n",
    "                        else :\n",
    "                            cov_sub_scaled = [ [(k-sub_win[0]), v] for k,v in cov_sub.items() ]\n",
    "\n",
    "                        positions.extend([ i[0] for i in cov_sub_scaled ])\n",
    "                        counts.extend([ i[1] for i in cov_sub_scaled ])\n",
    "            tracker += 1\n",
    "            print(f'{tracker} of {total_windows} ({ round(( (tracker)/(total_windows) )*100,2) }%) windows processed', end='\\r')\n",
    "\n",
    "                \n",
    "    # if no windows are specified\n",
    "    else :\n",
    "        total_genes = len(cov.keys())\n",
    "        tracker = 0\n",
    "        for gene,subdict in cov.items() :\n",
    "            if scaling : \n",
    "                positions.extend([ round(100*(i/transcript_sizes[gene])*5/5) for i in list(subdict.keys()) ])\n",
    "            else : \n",
    "                positions.extend(list(subdict.keys()))\n",
    "                \n",
    "            counts.extend(list(subdict.values()))\n",
    "            \n",
    "            tracker += 1\n",
    "            print(f'{tracker} of {total_genes} ({ round(( (tracker)/(total_genes) )*100,2) }%) transcripts processed', end='\\r')\n",
    "    \n",
    "    \n",
    "    df1 = pd.DataFrame({\n",
    "        'pos' : positions,\n",
    "        'count' : counts, \n",
    "        'alias' : sample, \n",
    "        'type' : 'density'\n",
    "    })\n",
    "    \n",
    "    #df1['pos'] = df1.apply(lambda x : adjust_pos(x['pos']), axis = 1)\n",
    "        \n",
    "    #df2 = pd.DataFrame({\n",
    "    #    'pos' : list(p5_pos.keys()),\n",
    "    #    'count' : list(p5_pos.values()), \n",
    "    #    'alias' : sample, \n",
    "    #    'type' : 'five_prime'\n",
    "    #})\n",
    "    \n",
    "    #df = df1 #pd.concat([df1, df2], ignore_index=True)\n",
    "\n",
    "    res = df1.groupby(['pos', 'alias', 'type'])['count'].sum().reset_index()\n",
    "    \n",
    "    if scaling :\n",
    "        if windows : \n",
    "            res = res.query('pos < 100 & pos > 0')\n",
    "            \n",
    "    time2 = time.time() \n",
    "    print(f\"Processing {os.path.basename(bed)} took {round(time2-time1, 3)} s.\\n\")\n",
    "    \n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a73f841a-6aaa-4ae8-8a87-a4faf23d986d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_metagene(bed_input, bed_windows = None, scaling = False, transcripts = None, sample = None, p5nt = ['G', 'A'], min_len = 21, max_len = 23) : \n",
    "    \n",
    "    if bed_windows : \n",
    "        my_windows = parse_windows(bed_windows)\n",
    "    else : \n",
    "        my_windows = None\n",
    "        \n",
    "    if transcripts : \n",
    "        transcript_info = parse_transcripts(transcripts)\n",
    "        transcript_sizes = transcript_info[1]\n",
    "    else : \n",
    "        transcript_sizes = None\n",
    "        \n",
    "    bed_string = f\".{os.path.basename(bed_windows).replace('.bed', '')}\" if bed_windows is not None else \"\"\n",
    "    \n",
    "    if type(bed_input) is list : \n",
    "        for i,F in enumerate(bed_input) : \n",
    "            my_coords = calculate_metagene_coord(\n",
    "                F, \n",
    "                windows = my_windows, \n",
    "                scaling = scaling, \n",
    "                transcript_sizes = transcript_sizes, \n",
    "                sample = os.path.basename(F).split(\".\")[0], \n",
    "                p5nt = p5nt,\n",
    "                min_len = min_len, \n",
    "                max_len = max_len)\n",
    "            \n",
    "            if i == 0 :\n",
    "                result = my_coords\n",
    "            else : \n",
    "                result = pd.concat([result, my_coords], ignore_index=True)\n",
    "        \n",
    "        plot_metagene(result)\n",
    "        return result\n",
    "    else : \n",
    "        my_coords = calculate_metagene_coord(\n",
    "            bed_input, \n",
    "            windows = my_windows, \n",
    "            scaling = scaling, \n",
    "            transcript_sizes = transcript_sizes, \n",
    "            sample = sample, \n",
    "            p5nt = p5nt,\n",
    "            min_len = min_len, \n",
    "            max_len = max_len)\n",
    "        \n",
    "        plot_metagene(result, title = f'{bed_string}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d747919f-ddfa-404e-82e0-6f2f42c2d911",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_counting(bed_input, bed_windows = None, scaling = False, transcripts = None, sample = None, p5nt = ['G', 'A'], min_len = 21, max_len = 23) : \n",
    "    \n",
    "    if bed_windows : \n",
    "        my_windows = parse_windows(bed_windows)\n",
    "    else : \n",
    "        my_windows = None\n",
    "        \n",
    "    if transcripts : \n",
    "        transcript_info = parse_transcripts(transcripts)\n",
    "        transcript_sizes = transcript_info[1]\n",
    "    else : \n",
    "        transcript_sizes = None\n",
    "        \n",
    "    bed_string = f\".{os.path.basename(bed_windows).replace('.bed', '')}\" if bed_windows is not None else \"\"\n",
    "    \n",
    "    if type(bed_input) is list : \n",
    "        for i,F in enumerate(bed_input) : \n",
    "            me_counts = sum_metagene_count_per_gene(\n",
    "                F, \n",
    "                windows = my_windows, \n",
    "                scaling = scaling, \n",
    "                transcript_sizes = transcript_sizes, \n",
    "                sample = os.path.basename(F).split(\".\")[0], \n",
    "                p5nt = p5nt,\n",
    "                min_len = min_len, \n",
    "                max_len = max_len)\n",
    "            \n",
    "            if i == 0 :\n",
    "                result = me_counts\n",
    "            else : \n",
    "                result = result.merge(me_counts, how = 'outer', on = 'gene')\n",
    "        \n",
    "        return result\n",
    "    else : \n",
    "        me_counts = sum_metagene_count_per_gene(\n",
    "            bed_input, \n",
    "            windows = my_windows, \n",
    "            scaling = scaling, \n",
    "            transcript_sizes = transcript_sizes, \n",
    "            sample = sample, \n",
    "            p5nt = p5nt,\n",
    "            min_len = min_len, \n",
    "            max_len = max_len)\n",
    "        \n",
    "        return me_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ae40b3e-50c3-40cf-bf57-63274dcbb206",
   "metadata": {},
   "source": [
    "## Plot csr-1 and wago-9 IP data relative to exon-exon junctions on CSR-1 targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fb67e21d-0a78-4ad2-b000-26f435826ff8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/fs/ess/PCON0160/ben/pipelines/nextflow_metagene'"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "ae59093d-702a-4597-9bc2-237082f0212c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# reformat bed.tsv file\n",
    "dir=/fs/ess/PAS1473/znfx1_CSRIP_WAGO9IP/metagene_alignment/transcripts\n",
    "outdir=$dir/reformat\n",
    "\n",
    "[ ! -d $outdir ] && mkdir -p $outdir\n",
    "\n",
    "for f in $(ls $dir/*.bed.tsv); do \n",
    "    \n",
    "    name=$(basename $f .bed.tsv)\n",
    "    cat $f |\\\n",
    "        awk -F'\\t' '{OFS=\"\\t\"; print $1,$2,$3,$4,$8,$6}' > $outdir/$name.rpm\n",
    "\n",
    "done\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3d90007c-462d-445a-a4bb-8141224df66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bed_input = \"/fs/ess/PAS1473/znfx1_CSRIP_WAGO9IP/metagene_alignment/transcripts/reformat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "718ffd51-6200-44b6-8174-925d49fd0015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/wago9_targets.eejunc.bed\" | grep upstream > wago9_targets_up_eejunc.bed\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/wago9_targets.eejunc.bed\" | grep downstream > wago9_targets_down_eejunc.bed\n",
    "\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/csr1_targets.eejunc.bed\" | grep upstream > csr1_targets_up_eejunc.bed\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/csr1_targets.eejunc.bed\" | grep downstream > csr1_targets_down_eejunc.bed\n",
    "\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/wago9_targets.eejunc.bed\" | grep upstream | awk -F'\\t' '{OFS=\"\\t\"; print $1,$3-500,$3+500}' > wago9_targets_centered_eejunc.bed\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/csr1_targets.eejunc.bed\" | grep upstream | awk -F'\\t' '{OFS=\"\\t\"; print $1,$3-500,$3+500}' > csr1_targets_centered_eejunc.bed\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a08a28-184d-4ba8-844f-2dd29b3d4f67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# full length \n",
    "wago = run_metagene(glob.glob(f\"{bed_input}/*.rpm\"), \n",
    "             bed_windows = \"wago9_targets_centered_eejunc.bed\", \n",
    "             scaling = False,\n",
    "             transcripts = None,\n",
    "             sample = \"upstream\", \n",
    "             p5nt = ['G', 'A'], \n",
    "             min_len = 21, \n",
    "             max_len = 23)\n",
    "\n",
    "csr = run_metagene(glob.glob(f\"{bed_input}/*.rpm\"), \n",
    "             bed_windows = \"csr1_targets_centered_eejunc.bed\", \n",
    "             scaling = False,\n",
    "             transcripts = None,\n",
    "             sample = \"upstream\", \n",
    "             p5nt = ['G', 'A'], \n",
    "             min_len = 21, \n",
    "             max_len = 23)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9495f214-4db9-4d2b-ae3c-d596e27ec9f8",
   "metadata": {},
   "source": [
    "# Calculate density in window per gene for CSR-1 targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed09c56-756f-40d5-9154-b0ee1667a351",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/csr1_targets.all.processed.bed\" | grep -w upstream_last_exon > upstream_last_exon_csr.bed\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/csr1_targets.all.processed.bed\" | grep -w last_exon > last_exon_csr.bed\n",
    "cat \"/fs/ess/PCON0160/ben/genomes/c_elegans/WS279/csr1_targets.all.processed.bed\" | grep -w three_prime_utr > three_prime_utr_csr.bed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e2f154ca-e787-43b5-a835-b136e7d66341",
   "metadata": {},
   "outputs": [],
   "source": [
    "upstream_eejunc = run_counting(glob.glob(f\"{bed_input}/*csr1*.rpm\"), \n",
    "             bed_windows = \"upstream_last_exon_csr.bed\", \n",
    "             scaling = False,\n",
    "             transcripts = None,\n",
    "             sample = \"upstream_last_exon\", \n",
    "             p5nt = ['G', 'A'], \n",
    "             min_len = 21, \n",
    "             max_len = 23)\n",
    "\n",
    "upstream_eejunc.to_csv(\"upstream_last_exon_csr.tsv\", sep = \"\\t\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b4d6f9f5-0bd2-4cea-a551-54bf8b282847",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_exon = run_counting(glob.glob(f\"{bed_input}/*csr1*.rpm\"), \n",
    "             bed_windows = \"last_exon_csr.bed\", \n",
    "             scaling = False,\n",
    "             transcripts = None,\n",
    "             sample = \"last_exon\", \n",
    "             p5nt = ['G', 'A'], \n",
    "             min_len = 21, \n",
    "             max_len = 23)\n",
    "\n",
    "last_exon.to_csv(\"last_exon_csr.tsv\", sep = \"\\t\", header = True, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9d9720d9-a19e-4583-855f-0e9105e4ce1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "three_prime_utr_csr = run_counting(glob.glob(f\"{bed_input}/*csr1*.rpm\"), \n",
    "             bed_windows = \"three_prime_utr_csr.bed\", \n",
    "             scaling = False,\n",
    "             transcripts = None,\n",
    "             sample = \"three_prime_utr\", \n",
    "             p5nt = ['G', 'A'], \n",
    "             min_len = 21, \n",
    "             max_len = 23)\n",
    "\n",
    "three_prime_utr_csr.to_csv(\"three_prime_utr_csr.tsv\", sep = \"\\t\", header = True, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
