{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6870cc3-7a70-4861-9e30-c884fcd5c6a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd \n",
    "import argparse\n",
    "import numpy as np \n",
    "import glob\n",
    "import time \n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing import  Pool\n",
    "import time\n",
    "import logging\n",
    "from functools import partial\n",
    "import random\n",
    "from functools import reduce\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7262a8e-bf50-41c7-aaf9-60d80e8a9a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metagene(result, plot_group = 'alias', facet_by = None, x_col = 'pos', y_col = 'count', shade = None, title = None, sharey = False, vline = False, ylim = None) : \n",
    "    \n",
    "    plot = sns.FacetGrid(result, \n",
    "                         col = facet_by, \n",
    "                         hue = plot_group, \n",
    "                         height = 4, \n",
    "                         aspect = 1.3, \n",
    "                        col_wrap = 2)\n",
    "\n",
    "    plot.map(sns.lineplot, x_col, y_col)\n",
    "        \n",
    "    plot.add_legend()\n",
    "    \n",
    "    if shade : \n",
    "            result['m'] = result[y_col] - result[shade]\n",
    "            result['M'] = result[y_col] + result[shade]\n",
    "            plot.map(plt.fill_between, x_col, 'm', 'M', alpha=0.2)\n",
    "            \n",
    "    if vline : \n",
    "        plt.axvline(x = vline, color = 'grey', label = f'{vline} bp', alpha = 0.5)\n",
    "    \n",
    "    \n",
    "    if title : \n",
    "        plot.fig.suptitle(f'{title}')\n",
    "        \n",
    "    if ylim : \n",
    "        plot.set(ylim=(0, ylim))\n",
    "    \n",
    "    return plot\n",
    "\n",
    "def merge_and_plot(conditions, result, count = 'count', vline = False, ylim = None, facet_by = 'type') :\n",
    "    \n",
    "    result_merge = result.merge(\n",
    "        conditions, how = 'left', left_on = 'alias', right_on = 'simple_name')\n",
    "    \n",
    "    result_grouped = result_merge.groupby(\n",
    "        ['pos', 'type', 'condition']\n",
    "    ).agg(\n",
    "        M = (count, 'mean'),\n",
    "        S = (count, 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    plot_metagene(result_grouped, \n",
    "                  shade = 'S', \n",
    "                  facet_by='type', \n",
    "                  x_col = 'pos', \n",
    "                  y_col = 'M', \n",
    "                  plot_group = 'condition',\n",
    "                  vline = vline,\n",
    "                  ylim = ylim\n",
    "                 )\n",
    "    \n",
    "    return result_grouped\n",
    "\n",
    "def parse_transcripts(transcripts) : \n",
    "    \n",
    "    windows = {}\n",
    "    seq = ''\n",
    "    i = 0\n",
    "    with open(transcripts, 'r') as f : \n",
    "        for line in f :\n",
    "            if line.startswith(\">\") :\n",
    "                info = line.strip().replace(\">\",\"\")\n",
    "                if i == 1 :\n",
    "                    windows[info] = [ [0, len(seq)] ]\n",
    "                    seq = ''\n",
    "                    i = 0\n",
    "                i += 1\n",
    "            else : \n",
    "                seq += line.strip()\n",
    "        else : \n",
    "            windows[info] = [ [0, len(seq)] ]\n",
    "    \n",
    "    return windows\n",
    "\n",
    "def parse_windows(bed_windows) : \n",
    "\n",
    "    windows = {}\n",
    "    \n",
    "    if isinstance(bed_windows, pd.DataFrame) : \n",
    "        for index,row in bed_windows.iterrows() : \n",
    "            \n",
    "            gene = bed_windows.iloc[index][0]\n",
    "            start = int(bed_windows.iloc[index][1])\n",
    "            end = int(bed_windows.iloc[index][2])\n",
    "            \n",
    "            if gene in windows.keys() : \n",
    "                    windows[gene].append([start, end])\n",
    "            else : \n",
    "                windows[gene] = [ [start, end] ]\n",
    "    else :\n",
    "        with open(bed_windows, 'r') as f : \n",
    "            for line in f : \n",
    "                info = line.strip().split(\"\\t\")\n",
    "                gene = info[0]\n",
    "                start = int(info[1])\n",
    "                end = int(round(float(info[2])))\n",
    "\n",
    "                if gene in windows.keys() : \n",
    "                    windows[gene].append([start, end])\n",
    "                else : \n",
    "                    windows[gene] = [ [start, end] ]\n",
    "                    \n",
    "    print(f\"Number of windows/transcripts: {len(windows)}\")\n",
    "    return windows\n",
    "\n",
    "def calculate_coverage(bed, p5nt = ['G', 'A'], min_len = 21, max_len = 23, aggregate = 'density') : \n",
    "    \n",
    "    bed_entries = 0 \n",
    "    with open(bed, 'r') as f : \n",
    "        for line in f : \n",
    "            bed_entries += 1\n",
    "    f.close()\n",
    "        \n",
    "    cov = {}\n",
    "    bed_line = 0\n",
    "    with open(bed, 'r') as f :\n",
    "        for line in f : \n",
    "            if not (line.startswith('chrom')) and not (line.startswith(\"gene_name\")) : \n",
    "                info = line.strip().split('\\t')\n",
    "                chrom = info[0]\n",
    "                start = int(info[1])\n",
    "                end = int(info[2])\n",
    "                seq = str(info[3])\n",
    "                five_prime = seq[0]\n",
    "                \n",
    "                if (five_prime in p5nt) and (len(seq) >= min_len and len(seq) <= max_len) : \n",
    "                    \n",
    "                    count = float(info[4])\n",
    "                    # make a dict for each gene + each 5' nucleotide\n",
    "                    # cov > gene > A > pos\n",
    "                    if not chrom in cov.keys() : \n",
    "                        cov[chrom] = {}\n",
    "                    \n",
    "                    \n",
    "                    if not five_prime in cov[chrom].keys() : \n",
    "                        cov[chrom][five_prime] = {}\n",
    "                        \n",
    "                    if aggregate == 'density' : \n",
    "                        for i in range(start, end + 1) :\n",
    "                            if i in cov[chrom][five_prime].keys() : \n",
    "                                cov[chrom][five_prime][i] += ( count / len(seq) )\n",
    "                            else : \n",
    "                                cov[chrom][five_prime][i] = ( count / len(seq) )\n",
    "                    elif aggregate == 'five_prime_position' : \n",
    "                        pos = end\n",
    "                        if pos in cov[chrom][five_prime].keys() : \n",
    "                            cov[chrom][five_prime][pos] += count\n",
    "                        else : \n",
    "                            cov[chrom][five_prime][pos] = count\n",
    "                    else : \n",
    "                        print('Aggregate must be set to either [density OR five_prime_position]')\n",
    "                        return 0 \n",
    "                    \n",
    "                        \n",
    "            bed_line += 1\n",
    "    f.close() \n",
    "    \n",
    "    pklf = f\"{bed}.cov.{''.join(p5nt)}.{aggregate}.pickle\"\n",
    "    with open(pklf, 'wb') as handle : \n",
    "        pickle.dump(cov, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return cov\n",
    "    \n",
    "def calculate_metagene_coord(bed, windows = None, scaling = False, sample = None, p5nt = ['G', 'A'], combine_five_prime_nt = False, aggregate = 'density', missing_data_as_0 = False, sum_coverage = False) :\n",
    "    \n",
    "    time1 = time.time()\n",
    "\n",
    "    pklf = f\"{bed}.cov.{''.join(p5nt)}.{aggregate}.pickle\"\n",
    "\n",
    "    if not os.path.exists(pklf) : \n",
    "        meta_info = calculate_coverage(bed, p5nt = p5nt, aggregate = aggregate)\n",
    "    else : \n",
    "        with open(pklf, 'rb') as handle : \n",
    "            meta_info = pickle.load(handle)\n",
    "    \n",
    "    if not sample : \n",
    "        sample = os.path.basename(bed).split(\".\")[0]\n",
    "    \n",
    "    positions = []\n",
    "    counts = []\n",
    "    five_prime_nts = []\n",
    "    genes = []\n",
    "    \n",
    "    if not windows : \n",
    "        return 0\n",
    "    \n",
    "    total_windows = len(windows.keys())\n",
    "    tracker = 1\n",
    "    for gene,win_coord in windows.items() :\n",
    "        for sub_win in win_coord :\n",
    "            if gene in meta_info.keys() :\n",
    "                for nt in meta_info[gene].keys() : \n",
    "                    if nt in p5nt :\n",
    "                        cov = meta_info[gene][nt]\n",
    "                        cov_sub = {}\n",
    "                        \n",
    "                        for i in range(sub_win[0], sub_win[1]+1) : \n",
    "                            if i in cov.keys() : \n",
    "                                cov_sub[i] = cov[i]\n",
    "                            else : \n",
    "                                if missing_data_as_0 :\n",
    "                                    cov_sub[i] = 0\n",
    "                                    \n",
    "                        if bool(cov_sub) : \n",
    "\n",
    "                            win_size = sub_win[1] - sub_win[0] + 1\n",
    "\n",
    "                            if scaling :\n",
    "                                cov_sub_scaled = [ [(round(100*( (k-sub_win[0])/win_size)*5)/5), v] for k,v in cov_sub.items() ] \n",
    "                            else :\n",
    "                                cov_sub_scaled = [ [(k-sub_win[0]), v] for k,v in cov_sub.items() ]\n",
    "\n",
    "                            positions.extend([ i[0] for i in cov_sub_scaled ])\n",
    "                            counts.extend([ i[1] for i in cov_sub_scaled ])\n",
    "                            genes.extend([ gene*len(cov_sub_scaled) ])\n",
    "\n",
    "                            if combine_five_prime_nt : \n",
    "                                five_prime_nts.extend([ ','.join(p5nt) for i in range(0,len(cov_sub_scaled)) ])\n",
    "                            else : \n",
    "                                five_prime_nts.extend([ nt for i in range(0,len(cov_sub_scaled)) ])\n",
    "        \n",
    "        #print(f'{tracker} of {total_windows} ({ round(( (tracker)/(total_windows) )*100,2) }%) genes processed', end='\\r')\n",
    "        tracker += 1\n",
    "\n",
    "    df1 = pd.DataFrame({\n",
    "        'pos' : positions,\n",
    "        'count' : counts, \n",
    "        'five_prime_nt' : five_prime_nts,\n",
    "        'alias' : f\"{sample}\", \n",
    "        'type' : 'density',\n",
    "        'gene' : genes\n",
    "    })\n",
    "    \n",
    "    if not sum_coverage : \n",
    "        res = df1.groupby(['pos', 'alias', 'type', 'five_prime_nt'])['count'].sum().reset_index()\n",
    "    else :\n",
    "        res = df1.groupby(['gene', 'alias', 'type', 'five_prime_nt'])['count'].sum().reset_index()\n",
    "    \n",
    "    res['zscore'] = 2**((res['count'] - res['count'].mean())/res['count'].std(ddof=0))\n",
    "    \n",
    "    if not sum_coverage : \n",
    "        if scaling :\n",
    "            if windows :\n",
    "                res = res.query('pos < 100 & pos > 0')\n",
    "            \n",
    "    time2 = time.time() \n",
    "    print(f\"Processing {sample} took {time2 - time1} s\")\n",
    "    \n",
    "    return res\n",
    "\n",
    "def parallel_cov(files, func, windows = None, scaling = False, sample = None, p5nt = ['G', 'A'], combine_five_prime_nt = False, aggregate = 'density', missing_data_as_0 = False, sum_coverage = False, n_cores = multiprocessing.cpu_count()-1) : \n",
    "    \n",
    "    \"\"\" Parallelize coverage calculation \"\"\"\n",
    "    \n",
    "    args = []\n",
    "    for f in files : \n",
    "        args.append([f] + [windows, scaling, sample] + [p5nt] + [combine_five_prime_nt] + [aggregate] + [missing_data_as_0] + [sum_coverage])\n",
    "    pool = Pool(n_cores)\n",
    "    df = pd.concat(pool.starmap(func, args))\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    \n",
    "    return df\n",
    "\n",
    "def run_metagene(bed_input, bed_windows = None, scaling = False, transcripts = None, sample = None, p5nt = None, min_len = 21, max_len = 23, sum_coverage = False, combine_five_prime_nt = False, aggregate = 'density', missing_data_as_0 = False) : \n",
    "    \n",
    "    if isinstance(bed_windows, pd.DataFrame) : \n",
    "        my_windows = parse_windows(bed_windows)\n",
    "    elif bed_windows : \n",
    "        my_windows = parse_windows(bed_windows)\n",
    "    elif transcripts :\n",
    "        my_windows = parse_transcripts(transcripts)\n",
    "    else :\n",
    "        print(\"Neither bed or transcripts provided...exiting\")\n",
    "        return 0\n",
    "    \n",
    "    if not p5nt : \n",
    "        p5nt = ['G', 'A']\n",
    "    \n",
    "    print(f'Calculating metagene coordinates for {min_len} to {max_len} RNAs starting with {\", \".join(p5nt)}')\n",
    "\n",
    "    if scaling : \n",
    "        if isinstance(bed_windows, pd.DataFrame) : \n",
    "            pass\n",
    "        elif bed_windows or transcripts : \n",
    "            pass\n",
    "        else : \n",
    "            print(\"If scaling is enable must provide either bed windows OR transcripts\")\n",
    "            return 0\n",
    "        \n",
    "    if aggregate != 'density' and aggregate != 'five_prime_position' : \n",
    "        print('Aggregate must be set to either [density OR five_prime_position]')\n",
    "        return 0 \n",
    "    \n",
    "    if not isinstance(bed_windows, pd.DataFrame) :\n",
    "        bed_string = f\".{os.path.basename(bed_windows).replace('.bed', '')}\" if bed_windows is not None else \"\"\n",
    "    else : \n",
    "        bed_string = \"my plot\"\n",
    "    \n",
    "    if type(bed_input) is list :\n",
    "        result = parallel_cov(bed_input,\n",
    "                              calculate_metagene_coord,\n",
    "                              windows = my_windows,\n",
    "                              scaling = scaling,\n",
    "                              sample = sample,\n",
    "                              p5nt = p5nt,\n",
    "                              combine_five_prime_nt = combine_five_prime_nt,\n",
    "                              aggregate = aggregate,\n",
    "                              missing_data_as_0 = missing_data_as_0,\n",
    "                              sum_coverage = sum_coverage,\n",
    "                              n_cores = 16)\n",
    "        return result\n",
    "\n",
    "def pad_bedfile(bed) : \n",
    "    \n",
    "    bed['start'] = bed.apply( lambda x : x['end']-100 if (x['end']-100) >= 0 else 0, axis = 1)\n",
    "    \n",
    "    bed['end'] = bed['end'] + 100\n",
    "    \n",
    "    #bed = bed[['gene', 'start', 'end']]\n",
    "    \n",
    "    return bed\n",
    "\n",
    "def reformat_bedfile(FILES, outdir) : \n",
    "    \n",
    "    if not os.path.exists(outdir) : \n",
    "        os.mkdir(outdir)\n",
    "        \n",
    "    for F in FILES : \n",
    "        name = os.path.basename(F).replace(\".bed.tsv\", \".rpm\")\n",
    "        outname = os.path.join(outdir, name)\n",
    "        \n",
    "        if not os.path.exists(name) :\n",
    "            \n",
    "            lines = ''\n",
    "            with open(F, 'r') as f : \n",
    "                for line in f : \n",
    "                    if not line.startswith(\"gene\") : \n",
    "                        info = line.strip().split(\"\\t\")\n",
    "                        lines += f\"{info[0]}\\t{info[1]}\\t{info[2]}\\t{info[3]}\\t{info[7]}\\t{info[5]}\\n\"\n",
    "            f.close()\n",
    "\n",
    "            out = open(outname, 'w')\n",
    "            out.write(lines)\n",
    "            out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
