{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e58d23-3e25-4fb1-b132-f7bf333b96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd \n",
    "import argparse\n",
    "import numpy as np \n",
    "import glob\n",
    "import time \n",
    "import logging\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "\n",
    "def plot_metagene(result, plot_group = 'alias', facet_by = None, x_col = 'pos', y_col = 'count', shade = None, title = None, sharey = False, vline = False, ylim = None) : \n",
    "    \n",
    "    plot = sns.FacetGrid(result, \n",
    "                         col = facet_by, \n",
    "                         hue = plot_group, \n",
    "                         height = 4, \n",
    "                         aspect = 1.3)\n",
    "\n",
    "    plot.map(sns.lineplot, x_col, y_col)\n",
    "        \n",
    "    plot.add_legend()\n",
    "    \n",
    "    if shade : \n",
    "            result['m'] = result[y_col] - result[shade]\n",
    "            result['M'] = result[y_col] + result[shade]\n",
    "            plot.map(plt.fill_between, x_col, 'm', 'M', alpha=0.2)\n",
    "            \n",
    "    if vline : \n",
    "        plt.axvline(x = vline, color = 'grey', label = f'{vline} bp', alpha = 0.5)\n",
    "    \n",
    "    \n",
    "    if title : \n",
    "        plot.fig.suptitle(f'{title}')\n",
    "        \n",
    "    if ylim : \n",
    "        plot.set(ylim=(0, ylim))\n",
    "    \n",
    "    return plot\n",
    "\n",
    "def merge_and_plot(conditions, result, count = 'count', vline = False, ylim = None, facet_by = 'type') :\n",
    "    \n",
    "    result_merge = result.merge(\n",
    "        conditions, how = 'left', left_on = 'alias', right_on = 'simple_name')\n",
    "    \n",
    "    result_grouped = result_merge.groupby(\n",
    "        ['pos', 'type', 'condition']\n",
    "    ).agg(\n",
    "        M = (count, 'mean'),\n",
    "        S = (count, 'std')\n",
    "    ).reset_index()\n",
    "    \n",
    "    plot_metagene(result_grouped, \n",
    "                  shade = 'S', \n",
    "                  facet_by='type', \n",
    "                  x_col = 'pos', \n",
    "                  y_col = 'M', \n",
    "                  plot_group = 'condition',\n",
    "                  vline = vline,\n",
    "                  ylim = ylim\n",
    "                 )\n",
    "    \n",
    "    return result_grouped\n",
    "\n",
    "def parse_transcripts(transcripts) : \n",
    "    \n",
    "    sizes = {}\n",
    "    seqs = {}\n",
    "    seq = ''\n",
    "    i = 0\n",
    "    with open(transcripts, 'r') as f : \n",
    "        for line in f :\n",
    "            if line.startswith(\">\") :\n",
    "                info = line.strip().replace(\">\",\"\")\n",
    "                if i == 1 :\n",
    "                    seqs[info] = seq \n",
    "                    sizes[info] = len(seq)\n",
    "                    seq = ''\n",
    "                    i = 0\n",
    "                i += 1\n",
    "            else : \n",
    "                seq += line.strip()\n",
    "                \n",
    "    return seqs, sizes\n",
    "\n",
    "def parse_windows(bed_windows) : \n",
    "\n",
    "    windows = {}\n",
    "    \n",
    "    if isinstance(bed_windows, pd.DataFrame) : \n",
    "        for index,row in bed_windows.iterrows() : \n",
    "            \n",
    "            gene = bed_windows.iloc[index][0]\n",
    "            start = int(bed_windows.iloc[index][1])\n",
    "            end = int(bed_windows.iloc[index][2])\n",
    "            \n",
    "            if gene in windows.keys() : \n",
    "                    windows[gene].append([start, end])\n",
    "            else : \n",
    "                windows[gene] = [ [start, end] ]\n",
    "\n",
    "    \n",
    "    else :\n",
    "        with open(bed_windows, 'r') as f : \n",
    "            for line in f : \n",
    "                info = line.strip().split(\"\\t\")\n",
    "                gene = info[0]\n",
    "                start = int(info[1])\n",
    "                end = int(round(float(info[2])))\n",
    "\n",
    "                if gene in windows.keys() : \n",
    "                    windows[gene].append([start, end])\n",
    "                else : \n",
    "                    windows[gene] = [ [start, end] ]\n",
    "    return windows\n",
    "\n",
    "def calculate_coverage(bed) : \n",
    "    \n",
    "    bed_entries = 0 \n",
    "    with open(bed, 'r') as f : \n",
    "        for line in f : \n",
    "            bed_entries += 1\n",
    "    f.close()\n",
    "    print(f\"{bed_entries} total bed entries...\")\n",
    "    \n",
    "    cov = {}\n",
    "    bed_line = 0\n",
    "    with open(bed, 'r') as f :\n",
    "        for line in f : \n",
    "            if not (line.startswith('chrom')) and not (line.startswith(\"gene_name\")) : \n",
    "                info = line.strip().split('\\t')\n",
    "                chrom = info[0]\n",
    "                start = int(info[1])\n",
    "                end = int(info[2])\n",
    "                seq = str(info[3])\n",
    "                count = float(info[4])\n",
    "                \n",
    "                # make a dict for each gene\n",
    "                if not chrom in cov.keys() : \n",
    "                    cov[chrom] = {}\n",
    "                \n",
    "                for i in range(start, end + 1) :\n",
    "                    if i in cov[chrom].keys() : \n",
    "                        cov[chrom][i] += ( count / len(seq) )\n",
    "                    else : \n",
    "                        cov[chrom][i] = ( count / len(seq) )\n",
    "                        \n",
    "            bed_line += 1\n",
    "            print(f'{bed_line} of {bed_entries} ({ round(( (bed_line)/(bed_entries) )*100,2) }%) total bed entries', end='\\r')\n",
    "    f.close() \n",
    "    \n",
    "    pklf = f\"{bed}.cov.pickle\"\n",
    "    with open(pklf, 'wb') as handle : \n",
    "        pickle.dump(cov, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "    return cov\n",
    "    \n",
    "def adjust_pos(pos) : \n",
    "    \n",
    "    if not pos == 100 and not pos == 0 : \n",
    "        return pos\n",
    "    elif pos == 100 : \n",
    "        return 99.8\n",
    "    else : \n",
    "        return 0.2\n",
    "    \n",
    "def sum_metagene_count_per_gene(bed, windows = None, scaling = False, transcript_sizes = None, sample = None, p5nt = ['G', 'A'], min_len = 21, max_len = 23) :\n",
    "    \n",
    "    time1 = time.time()\n",
    "        \n",
    "    pklf = f\"{bed}.cov.pickle\"\n",
    "    if not os.path.exists(pklf) : \n",
    "        cov = calculate_coverage(bed)\n",
    "    else : \n",
    "        with open(pklf, 'rb') as handle : \n",
    "            cov = pickle.load(handle)\n",
    "    \n",
    "    sample = os.path.basename(bed).split(\".\")[0]\n",
    "\n",
    "    counts = []\n",
    "    genes = []\n",
    "    if windows : \n",
    "        total_windows = len(windows.keys())\n",
    "        tracker = 0\n",
    "        for gene,win_coord in windows.items() :\n",
    "            for sub_win in win_coord :\n",
    "                if gene in cov.keys() :\n",
    "                    val = sum( [v for k,v in cov[gene].items() if sub_win[0] <= k <= sub_win[1]])\n",
    "                    if val :\n",
    "                        win_size = sub_win[1] - sub_win[0] + 1\n",
    "                        genes.append(f\"{gene}_{sub_win[0]}_{sub_win[1]}\")\n",
    "                        counts.append(val/win_size)\n",
    "                            \n",
    "           # tracker += 1\n",
    "            #print(f'{tracker} of {total_windows} ({ round(( (tracker)/(total_windows) )*100,2) }%) windows processed', end='\\r')\n",
    "    else : \n",
    "        total_genes = len(cov.keys())\n",
    "        tracker = 0\n",
    "        for gene,subdict in cov.items() :\n",
    "            val = sum(list(subdict.values()))\n",
    "            if val :\n",
    "                if gene in count.keys() : \n",
    "                    print(\"Multiple windows for 1 gene...exiting\")\n",
    "                    return 0\n",
    "                else : \n",
    "                    genes.append(gene)\n",
    "                    counts.append(count)\n",
    "    \n",
    "    df = pd.DataFrame({\n",
    "        'gene' : genes, \n",
    "        f'{sample}' : counts\n",
    "    })\n",
    "    df = df.drop_duplicates()\n",
    "    return df\n",
    "\n",
    "def calculate_metagene_coord(bed, windows = None, scaling = False, transcript_sizes = None, sample = None, p5nt = ['G', 'A'], min_len = 21, max_len = 23) :\n",
    "    \n",
    "    time1 = time.time()\n",
    "        \n",
    "    pklf = f\"{bed}.cov.pickle\"\n",
    "    if not os.path.exists(pklf) : \n",
    "        cov = calculate_coverage(bed)\n",
    "    else : \n",
    "        with open(pklf, 'rb') as handle : \n",
    "            cov = pickle.load(handle)\n",
    "    \n",
    "    positions = []\n",
    "    counts = []\n",
    "    if windows : \n",
    "        total_windows = len(windows.keys())\n",
    "        tracker = 0\n",
    "        for gene,win_coord in windows.items() :\n",
    "            for sub_win in win_coord :\n",
    "                if gene in cov.keys() : \n",
    "                    cov_sub = { k:v for k,v in cov[gene].items() if sub_win[0] <= k <= sub_win[1] }\n",
    "\n",
    "                    if bool(cov_sub) : \n",
    "                        win_size = sub_win[1] - sub_win[0] + 1\n",
    "\n",
    "                        if scaling :\n",
    "                            cov_sub_scaled = [ [(round(100*( (k-sub_win[0])/win_size)*5)/5), v] for k,v in cov_sub.items() ] \n",
    "                        else :\n",
    "                            cov_sub_scaled = [ [(k-sub_win[0]), v] for k,v in cov_sub.items() ]\n",
    "\n",
    "                        positions.extend([ i[0] for i in cov_sub_scaled ])\n",
    "                        counts.extend([ i[1]/total_windows for i in cov_sub_scaled ])\n",
    "            tracker += 1\n",
    "            print(f'{tracker} of {total_windows} ({ round(( (tracker)/(total_windows) )*100,2) }%) genes processed', end='\\r')\n",
    "\n",
    "                \n",
    "    # if no windows are specified\n",
    "    else :\n",
    "        total_genes = len(cov.keys())\n",
    "        tracker = 0\n",
    "        for gene,subdict in cov.items() :\n",
    "            if scaling : \n",
    "                positions.extend([ round(100*(i/transcript_sizes[gene])*5/5) for i in list(subdict.keys()) ])\n",
    "            else : \n",
    "                positions.extend(list(subdict.keys()))\n",
    "                \n",
    "            counts.extend(list(subdict.values()))\n",
    "            \n",
    "            tracker += 1\n",
    "            print(f'{tracker} of {total_genes} ({ round(( (tracker)/(total_genes) )*100,2) }%) transcripts processed', end='\\r')\n",
    "    \n",
    "    \n",
    "    df1 = pd.DataFrame({\n",
    "        'pos' : positions,\n",
    "        'count' : counts, \n",
    "        'alias' : sample, \n",
    "        'type' : 'density'\n",
    "    })\n",
    "    \n",
    "    res = df1.groupby(['pos', 'alias', 'type'])['count'].sum().reset_index()\n",
    "    \n",
    "    res['zscore'] = 2**((res['count'] - res['count'].mean())/res['count'].std(ddof=0))\n",
    "    \n",
    "    if scaling :\n",
    "        if windows : \n",
    "            res = res.query('pos < 100 & pos > 0')\n",
    "            \n",
    "    time2 = time.time() \n",
    "    print(f\"Processing {os.path.basename(bed)} took {round(time2-time1, 3)} s.\\n\")\n",
    "    \n",
    "    return res\n",
    "\n",
    "def run_metagene(bed_input, bed_windows = None, scaling = False, transcripts = None, sample = None, p5nt = ['G', 'A'], min_len = 21, max_len = 23) : \n",
    "    \n",
    "    if isinstance(bed_windows, pd.DataFrame) : \n",
    "        my_windows = parse_windows(bed_windows)\n",
    "    elif bed_windows : \n",
    "        my_windows = parse_windows(bed_windows)\n",
    "    else : \n",
    "        my_windows = None\n",
    "        \n",
    "    if transcripts : \n",
    "        transcript_info = parse_transcripts(transcripts)\n",
    "        transcript_sizes = transcript_info[1]\n",
    "    else : \n",
    "        transcript_sizes = None\n",
    "        \n",
    "    if scaling : \n",
    "        if bed_windows or transcripts : \n",
    "            pass\n",
    "        else : \n",
    "            print(\"If scaling is enable must provide either bed windows OR transcripts\")\n",
    "            return 0\n",
    "    \n",
    "    if not isinstance(bed_windows, pd.DataFrame) :\n",
    "        bed_string = f\".{os.path.basename(bed_windows).replace('.bed', '')}\" if bed_windows is not None else \"\"\n",
    "    else : \n",
    "        bed_string = \"my plot\"\n",
    "    \n",
    "    if type(bed_input) is list : \n",
    "        for i,F in enumerate(bed_input) : \n",
    "            my_coords = calculate_metagene_coord(\n",
    "                F, \n",
    "                windows = my_windows, \n",
    "                scaling = scaling, \n",
    "                transcript_sizes = transcript_sizes, \n",
    "                sample = os.path.basename(F).split(\".\")[0], \n",
    "                p5nt = p5nt,\n",
    "                min_len = min_len, \n",
    "                max_len = max_len)\n",
    "            \n",
    "            if i == 0 :\n",
    "                result = my_coords\n",
    "            else : \n",
    "                result = pd.concat([result, my_coords], ignore_index=True)\n",
    "        \n",
    "        plot_metagene(result)\n",
    "        return result\n",
    "    else : \n",
    "        my_coords = calculate_metagene_coord(\n",
    "            bed_input, \n",
    "            windows = my_windows, \n",
    "            scaling = scaling, \n",
    "            transcript_sizes = transcript_sizes, \n",
    "            sample = sample, \n",
    "            p5nt = p5nt,\n",
    "            min_len = min_len, \n",
    "            max_len = max_len)\n",
    "        \n",
    "        plot_metagene(result, ycol = 'zscore', title = f'{bed_string}')  \n",
    "        \n",
    "def run_counting(bed_input, bed_windows = None, scaling = False, transcripts = None, sample = None, p5nt = ['G', 'A'], min_len = 21, max_len = 23) : \n",
    "    \n",
    "    if isinstance(bed_windows, pd.DataFrame) : \n",
    "        my_windows = parse_windows(bed_windows)\n",
    "    elif bed_windows : \n",
    "        my_windows = parse_windows(bed_windows)\n",
    "    else : \n",
    "        my_windows = None\n",
    "        \n",
    "    if transcripts : \n",
    "        transcript_info = parse_transcripts(transcripts)\n",
    "        transcript_sizes = transcript_info[1]\n",
    "    else : \n",
    "        transcript_sizes = None\n",
    "        \n",
    "    bed_string = f\".{os.path.basename(bed_windows).replace('.bed', '')}\" if bed_windows is not None else \"\"\n",
    "    \n",
    "    if type(bed_input) is list : \n",
    "        for i,F in enumerate(bed_input) : \n",
    "            me_counts = sum_metagene_count_per_gene(\n",
    "                F, \n",
    "                windows = my_windows, \n",
    "                scaling = scaling, \n",
    "                transcript_sizes = transcript_sizes, \n",
    "                sample = os.path.basename(F).split(\".\")[0], \n",
    "                p5nt = p5nt,\n",
    "                min_len = min_len, \n",
    "                max_len = max_len)\n",
    "            \n",
    "            if i == 0 :\n",
    "                result = me_counts\n",
    "            else : \n",
    "                result = result.merge(me_counts, how = 'outer', on = 'gene')\n",
    "        \n",
    "        return result\n",
    "    else : \n",
    "        me_counts = sum_metagene_count_per_gene(\n",
    "            bed_input, \n",
    "            windows = my_windows, \n",
    "            scaling = scaling, \n",
    "            transcript_sizes = transcript_sizes, \n",
    "            sample = sample, \n",
    "            p5nt = p5nt,\n",
    "            min_len = min_len, \n",
    "            max_len = max_len)\n",
    "        \n",
    "        return me_counts\n",
    "    \n",
    "def pad_bedfile(bed) : \n",
    "    \n",
    "    bed['start'] = bed.apply( lambda x : x['end']-100 if (x['end']-100) >= 0 else 0, axis = 1)\n",
    "    \n",
    "    bed['end'] = bed['end'] + 100\n",
    "    \n",
    "    #bed = bed[['gene', 'start', 'end']]\n",
    "    \n",
    "    \n",
    "    return bed\n",
    "\n",
    "def reformat_bedfile(FILES, outdir) : \n",
    "    \n",
    "    if not os.path.exists(outdir) : \n",
    "        os.mkdir(outdir)\n",
    "        \n",
    "    for F in FILES : \n",
    "        name = os.path.basename(F).replace(\".bed.tsv\", \".rpm\")\n",
    "        outname = os.path.join(outdir, name)\n",
    "        \n",
    "        if not os.path.exists(name) :\n",
    "            \n",
    "            lines = ''\n",
    "            with open(F, 'r') as f : \n",
    "                for line in f : \n",
    "                    if not line.startswith(\"gene\") : \n",
    "                        info = line.strip().split(\"\\t\")\n",
    "                        lines += f\"{info[0]}\\t{info[1]}\\t{info[2]}\\t{info[3]}\\t{info[7]}\\t{info[5]}\\n\"\n",
    "            f.close()\n",
    "\n",
    "            out = open(outname, 'w')\n",
    "            out.write(lines)\n",
    "            out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (Conda 2022.05) [python/3.9-2022.05]",
   "language": "python",
   "name": "python39_202205"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
